use anyhow::{anyhow, Context, Result};
use std::{collections::HashMap, fmt, io::Write, path::PathBuf};

// The name of the file generated by this crate, used in src/lib.rs
const GENERATED_FILE_NAME: &str = "tensorflow_proto_gen.rs";

// The default name of the tensorflow proto source if the TENSORFLOW_PROTO_SOURCE environment
// variable isn't defined.
const DEFAULT_TENSORFLOW_PROTO_SOURCE: &str = "./proto";

// The directory containing the protocol buffer source tree.
const TENSORFLOW_PROTO_SOURCE: Option<&str> = option_env!("TENSORFLOW_PROTO_SOURCE");

// The default extension to use to find protocol buffer definitions.
const DEFAULT_PROTO_FILE_EXT: &str = ".proto";

// The environment variable referring to the protocol buffer file extension
const PROTO_FILE_EXT: Option<&str> = option_env!("PROTO_FILE_EXT");

/// List of all types that we want to serde-ify.
///
/// When the boolean is `true` we also apply `#[serde(default)]` to allow users freedom of not
/// having to specify every single option exhaustively.
const SERDE_TYPES: &[(bool, &str)] = &[
    (false, ".tensorflow.AttrValue"),
    (false, "tensorflow.NameAttrList"),
    (false, ".tensorflow.ResourceHandleProto"),
    (false, "tensorflow.SessionMetadata"),
    (false, "tensorflow.TensorProto"),
    (false, ".tensorflow.TensorShapeProto"),
    (false, "tensorflow.VariantTensorDataProto"),
    (true, "tensorflow.AutoParallelOptions"),
    (true, "tensorflow.ClusterDef"),
    (true, "tensorflow.ConfigProto"),
    (true, "tensorflow.ConfigProto.Experimental"),
    (true, "tensorflow.GPUOptions"),
    (true, "tensorflow.GPUOptions.Experimental"),
    (true, "tensorflow.GPUOptions.Experimental.VirtualDevices"),
    (true, "tensorflow.GraphOptions"),
    (true, "tensorflow.JobDef"),
    (true, "tensorflow.OptimizerOptions"),
    (true, "tensorflow.RewriterConfig"),
    (true, "tensorflow.RewriterConfig.CustomGraphOptimizer"),
    (true, "tensorflow.RPCOptions"),
    (true, "tensorflow.ScopedAllocatorOptions"),
    (true, "tensorflow.ThreadPoolOptionProto"),
    (true, "tensorflow.VerifierConfig"),
    // List is could be more complete...
];

struct ModMap {
    name: String,
    include: Option<String>,
    children: HashMap<String, ModMap>,
}

impl fmt::Display for ModMap {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        writeln!(f, "pub mod {} {{", self.name)?;
        if let Some(ref include) = self.include {
            writeln!(f, r#"include!("{}");"#, include)?;
        }
        for value in self.children.values() {
            writeln!(f, "{}", value)?;
        }
        write!(f, "}}")
    }
}

fn file_name(path: impl AsRef<std::path::Path>) -> Result<String> {
    Ok(path
        .as_ref()
        .file_name()
        .ok_or_else(|| anyhow!("path has no file_name"))?
        .to_str()
        .ok_or_else(|| anyhow!("invalid unicode file_name"))?
        .to_owned())
}

fn serde_attributes(config: &mut prost_build::Config, name: &'static str, is_struct: bool) {
    config.type_attribute(name, "#[derive(serde::Deserialize, serde::Serialize)]");
    if is_struct {
        config.type_attribute(name, "#[serde(default)]");
    }
}
fn main() -> Result<()> {
    let out_dir = PathBuf::from(std::env::var("OUT_DIR")?);
    let suffix = PROTO_FILE_EXT.unwrap_or(DEFAULT_PROTO_FILE_EXT);
    let source = TENSORFLOW_PROTO_SOURCE
        .map_or_else(|| DEFAULT_TENSORFLOW_PROTO_SOURCE.into(), PathBuf::from);
    let schema_files = glob::glob(
        &source
            .join("**")
            .join(format!("*{}", suffix))
            .display()
            .to_string(),
    )?
    .collect::<Result<Vec<_>, _>>()?;

    for path in schema_files.iter() {
        println!("cargo:rerun-if-changed={}", path.display().to_string());
    }

    if !schema_files.is_empty() {
        let mut config = prost_build::Config::new();
        config.out_dir(&out_dir);
        if std::env::var_os("CARGO_FEATURE_SERDE").is_some() {
            for (is_struct, serde_type) in &SERDE_TYPES[..] {
                serde_attributes(&mut config, serde_type, *is_struct);
            }
        }
        config.compile_protos(&schema_files, &[source])?;
    }

    let mut root = HashMap::new();
    for result_entry in glob::glob(&out_dir.join("*.rs").display().to_string())? {
        let entry = result_entry?;
        let basename = file_name(&entry)?;
        if basename != GENERATED_FILE_NAME {
            let base_module_name = file_name(entry.with_extension(""))?;
            let mod_path = base_module_name
                .split('.')
                .map(ToOwned::to_owned)
                .collect::<Vec<_>>();
            let top = mod_path[0].clone();
            let rest = &mod_path[1..];
            let mut tree = root.entry(top.clone()).or_insert_with(|| ModMap {
                name: top,
                include: Default::default(),
                children: HashMap::new(),
            });
            for module in rest {
                tree.children
                    .entry(module.to_owned())
                    .or_insert_with(move || ModMap {
                        name: module.to_owned(),
                        include: None,
                        children: HashMap::new(),
                    });
                tree = tree
                    .children
                    .get_mut(module)
                    .ok_or_else(|| anyhow!("{} module not found", module))?;
            }
            tree.include = Some(basename);
        }
    }

    let mut file = std::fs::OpenOptions::new()
        .create(true)
        .truncate(true)
        .write(true)
        .open(out_dir.join(GENERATED_FILE_NAME))?;

    for (module, value) in root {
        writeln!(file, "{}", value).with_context(move || {
            format!(
                "failed to write rust module for tensorflow protobuf: {}",
                module
            )
        })?;
    }

    Ok(())
}
